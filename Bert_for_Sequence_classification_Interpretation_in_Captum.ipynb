{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Bert for Sequence classification Interpretation in Captum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NataliaDiaz/XAI-tutorials/blob/main/Bert_for_Sequence_classification_Interpretation_in_Captum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFESEuEgbUDD"
      },
      "source": [
        "# Interpretation of BertForSequenceClassification in captum\n",
        "\n",
        "In this notebook we use Captum to interpret a BERT sentiment classifier finetuned on the imdb dataset https://huggingface.co/lvwerra/bert-imdb "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ51JAxHbghp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "919a78d5-e1ab-4f44-b6b6-733256c0fbad"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install transformers\n",
        "!pip install captum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from captum) (1.18.2)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from captum) (1.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from captum) (3.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->captum) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS9Kaz8ubUDG"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "from captum.attr import visualization as viz\n",
        "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1yl1gdvbUDS"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U5XDt1Gb73t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6a6afd0-b80d-4aca-d4a9-782b4c45b66d"
      },
      "source": [
        "# Get model and config files from https://huggingface.co/lvwerra/bert-imdb\n",
        "!wget -P ./model https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/config.json\n",
        "!wget -P ./model https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/pytorch_model.bin\n",
        "!wget -P ./model https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/special_tokens_map.json\n",
        "!wget -P ./model https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/tokenizer_config.json\n",
        "!wget -P ./model https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/training_args.bin\n",
        "!wget -P ./model https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-13 08:27:20--  https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/config.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.131.101\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.131.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1220 (1.2K) [application/json]\n",
            "Saving to: ‘./model/config.json.2’\n",
            "\n",
            "\rconfig.json.2         0%[                    ]       0  --.-KB/s               \rconfig.json.2       100%[===================>]   1.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-13 08:27:20 (80.5 MB/s) - ‘./model/config.json.2’ saved [1220/1220]\n",
            "\n",
            "--2020-04-13 08:27:21--  https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/pytorch_model.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.131.101\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.131.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1334420863 (1.2G) [application/octet-stream]\n",
            "Saving to: ‘./model/pytorch_model.bin.2’\n",
            "\n",
            "pytorch_model.bin.2 100%[===================>]   1.24G  50.5MB/s    in 26s     \n",
            "\n",
            "2020-04-13 08:27:47 (49.3 MB/s) - ‘./model/pytorch_model.bin.2’ saved [1334420863/1334420863]\n",
            "\n",
            "--2020-04-13 08:27:48--  https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/special_tokens_map.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.38.222\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.38.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112 [application/json]\n",
            "Saving to: ‘./model/special_tokens_map.json.2’\n",
            "\n",
            "special_tokens_map. 100%[===================>]     112  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-13 08:27:48 (3.37 MB/s) - ‘./model/special_tokens_map.json.2’ saved [112/112]\n",
            "\n",
            "--2020-04-13 08:27:49--  https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/tokenizer_config.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.38.222\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.38.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40 [application/json]\n",
            "Saving to: ‘./model/tokenizer_config.json.2’\n",
            "\n",
            "tokenizer_config.js 100%[===================>]      40  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-13 08:27:50 (1.21 MB/s) - ‘./model/tokenizer_config.json.2’ saved [40/40]\n",
            "\n",
            "--2020-04-13 08:27:51--  https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/training_args.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.38.222\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.38.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1449 (1.4K) [application/octet-stream]\n",
            "Saving to: ‘./model/training_args.bin.2’\n",
            "\n",
            "training_args.bin.2 100%[===================>]   1.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-13 08:27:51 (89.7 MB/s) - ‘./model/training_args.bin.2’ saved [1449/1449]\n",
            "\n",
            "--2020-04-13 08:27:52--  https://s3.amazonaws.com/models.huggingface.co/bert/lvwerra/bert-imdb/vocab.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.205.61\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.205.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 213450 (208K) [text/plain]\n",
            "Saving to: ‘./model/vocab.txt.2’\n",
            "\n",
            "vocab.txt.2         100%[===================>] 208.45K   903KB/s    in 0.2s    \n",
            "\n",
            "2020-04-13 08:27:53 (903 KB/s) - ‘./model/vocab.txt.2’ saved [213450/213450]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-nyyq_tbUDa"
      },
      "source": [
        "# load model\n",
        "model = BertForSequenceClassification.from_pretrained('./model')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "model.zero_grad()\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('./model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUMsvUOTbUDi"
      },
      "source": [
        "def predict(inputs):\n",
        "    return model(inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIbauwGbbUDo"
      },
      "source": [
        "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
        "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
        "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcnTCNUFbUD1"
      },
      "source": [
        "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
        "\n",
        "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "    # construct input token ids\n",
        "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
        "    # construct reference token ids \n",
        "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
        "\n",
        "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
        "\n",
        "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
        "    seq_len = input_ids.size(1)\n",
        "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
        "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
        "    return token_type_ids, ref_token_type_ids\n",
        "\n",
        "def construct_input_ref_pos_id_pair(input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
        "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
        "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
        "\n",
        "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    return position_ids, ref_position_ids\n",
        "    \n",
        "def construct_attention_mask(input_ids):\n",
        "    return torch.ones_like(input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhasPia4bUD8"
      },
      "source": [
        "def custom_forward(inputs):\n",
        "    preds = predict(inputs)\n",
        "    return torch.softmax(preds, dim = 1)[0][1].unsqueeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGwkb1vAbUEA"
      },
      "source": [
        "lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQlVDaISbUEF"
      },
      "source": [
        "# One can test a couple of examples and check that the sentiment classifier is behaving\n",
        "text = \"The movie was one of those amazing movies\"\n",
        "#text = \"The movie was one of those crappy movies you can't forget.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtoFctjVbUEM"
      },
      "source": [
        "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
        "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
        "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
        "attention_mask = construct_attention_mask(input_ids)\n",
        "\n",
        "indices = input_ids[0].detach().tolist()\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4vlqBBrbUEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d880f30-8e99-4522-825f-0ab6861aaaf5"
      },
      "source": [
        "# Check predict output\n",
        "predict(input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.1333,  3.6520]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpNkwy6_bUEd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3c911f0-3bbc-4b7e-bdc2-bd2faf69dfe2"
      },
      "source": [
        "# Check output of custom_forward\n",
        "custom_forward(input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9989], device='cuda:0', grad_fn=<UnsqueezeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAzBqQlpbUEk"
      },
      "source": [
        "attributions, delta = lig.attribute(inputs=input_ids,\n",
        "                                    baselines=ref_input_ids,\n",
        "                                    n_steps=700,\n",
        "                                    internal_batch_size=3,\n",
        "                                    return_convergence_delta=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU8SRQFybUEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c5903435-c4ac-4e50-c24d-d5fb9d79edd3"
      },
      "source": [
        "score = predict(input_ids)\n",
        "\n",
        "print('Sentence: ', text)\n",
        "print('Sentiment: ' + str(torch.argmax(score[0]).cpu().numpy()) + \\\n",
        "      ', Probability positive: ' + str(torch.softmax(score, dim = 1)[0][1].cpu().detach().numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:  The movie was one of those amazing movies\n",
            "Sentiment: 1, Probability positive: 0.9988709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq8R_ZYubUEu"
      },
      "source": [
        "def summarize_attributions(attributions):\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    return attributions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q7xXwRrbUEx"
      },
      "source": [
        "attributions_sum = summarize_attributions(attributions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZF0RmZ4bUE1"
      },
      "source": [
        "# storing couple samples in an array for visualization purposes\n",
        "score_vis = viz.VisualizationDataRecord(attributions_sum,\n",
        "                                        torch.softmax(score, dim = 1)[0][1],\n",
        "                                        torch.argmax(torch.softmax(score, dim = 0)[0]),\n",
        "                                        1,\n",
        "                                        text,\n",
        "                                        attributions_sum.sum(),       \n",
        "                                        all_tokens,\n",
        "                                        delta)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gAojuO6ody0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b18a66b2-b242-4145-e215-831eadc7329c"
      },
      "source": [
        "print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
        "viz.visualize_text([score_vis])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m Visualization For Score \u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>The movie was one of those amazing movies</b></text></td><td><text style=\"padding-right:2em\"><b>0.26</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> one                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> those                    </font></mark><mark style=\"background-color: hsl(120, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> amazing                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movies                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXD4N9FogZu"
      },
      "source": [
        "The visualization is clearly meaningless! :(\n"
      ]
    }
  ]
}